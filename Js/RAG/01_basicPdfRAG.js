// load document by specifying the path
    // if it is already loaded then it is present in the cache
// split the document using chunking method you want
    // if it is already splitted then no need to do again
// embbed the splitted text
// store the embeddings in vector db

// embed the user query
// search vector db using the user's query embeddings
// feed it to the context of llm
// generate final output

